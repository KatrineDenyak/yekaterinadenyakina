<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Evaluating the Market Value of FIFA players using ML</title><style type="text/css"> * {margin:0; padding:0; text-indent:0; }
 body { background-color: #E7E6E6; }
 h1 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 26pt; }
 .s1 { color: #2F5496; font-family:Calibri, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 16pt; }
 p { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 11pt; margin:0pt; }
 .s2 { color: #2F5496; font-family:Calibri, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 13pt; }
 .s3 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; }
 .s4 { color: #1F3763; font-family:Calibri, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt; }
 .s5 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .s6 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: 7pt; }
 .s7 { color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; vertical-align: 7pt; }
 .s8 { color: #2F5496; font-family:Calibri, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 12pt; }
 .s11 { color: #00F; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 11pt; }
 .a { color: #00F; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 11pt; }
 li {display: block; }
 #l1 {padding-left: 0pt; }
 #l1> li>*:first-child:before {content: "• "; color: black; font-family:Arial, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 11pt; }
</style></head><body><p style="text-indent: 0pt;text-align: left;"/><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"/><h1 style="padding-left: 43pt;text-indent: 0pt;text-align: center;">Evaluating the Market Value of FIFA players using Machine Learning</h1><p class="s1" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark0">&zwnj;</a>Description and Motivation of the Problem</p><p style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">In the world of football, a player’s market valuation has gained substantial importance and interest after the 1995 Bosman ruling by the Court of Justice of the European Union, which fundamentally reshaped the dynamics of the transfer market (Europa.eu, 2024) by giving players’ freedom of movement when their contract expires. In 2019, 7.35 billion dollars was paid by clubs to recruit players protected by employment contracts (MEN PROFESSIONAL FOOTBALL A REVIEW OF INTERNATIONAL FOOTBALL TRANSFERS WORLDWIDE,</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 12pt;text-align: left;">n.d.).</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">This shows that the valuation of a player has a significant impact in the world of football. From the club&#39;s perspective, this takes place for decision-making purposes. On the other hand, it is also helpful for the players’ representatives to assess what value the club attaches to the athlete when negotiating his salary.</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">In Herm’s et al. research (Herm, Callsen-Bracker and Kreis, 2014), they try to define what the market value in the professional football world is as “an estimate of the amount of money a club would be willing to pay to make [an] athlete sign a contract, independent of an actual transaction.” “However, evaluating an individual&#39;s value within any kind of team – such as a soccer team – is a challenging task.”</p><p class="s2" style="padding-top: 11pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark1">&zwnj;</a>Significance and Implications</p><p style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">In an era where player transfers, contract negotiations, and market valuations dominate headlines, the question of their valuation is of great interest for all parties (clubs, players and intermediaries) who need to assess a players worth in the transfer market. Understanding the intrinsic and extrinsic factors influencing a player&#39;s worth becomes paramount. Journalist Kaplan states that “the competition to provide soccer statistics reflects the level of interest in them.” (Kaplan, 2010).</p><p class="s3" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;line-height: 109%;text-align: left;">Traditionally, analysts gauge a player&#39;s market value using notational analysis, focusing on key performance indicators derived from statistical summaries of video footage and goal metrics. However, this approach is becoming outdated as machine learning evolves, offering more efficient ways to analyse intricate relationships.</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">Leveraging <span class="s3">machine learning </span>along with AI techniques to predict players’ market value and determine the driving factors behind them not only aids clubs, agents, and stakeholders in crucial strategic decision-making but also provides a comprehensive perspective on talent valuation, market trends, and financial implications within the football ecosystem.</p><p style="padding-top: 12pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">With all this in mind, there is a clear motivation to explore the relations between different features of football players and their market value - how these features affect their overall market value. Which are the most important features to affect the Market Value? And to use that knowledge to predict the expected market value of any given player.</p><p class="s2" style="padding-top: 11pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark2">&zwnj;</a>Dataset Overview</p><p style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">The analysis focuses on the FIFA 2024 dataset encompassing player attributes, performance metrics, and market values across diverse clubs and countries. It is a comprehensive record of players, capturing their skills, strengths and weaknesses within the global football market.</p><p class="s4" style="padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark3">&zwnj;</a>Data Types and Relevance</p><ul id="l1"><li data-list-text="•"><p style="padding-top: 1pt;padding-left: 41pt;text-indent: -35pt;line-height: 12pt;text-align: left;">Discrete Variables: Player skill levels reflecting gameplay mechanics and roles.</p></li><li data-list-text="•"><p style="padding-left: 42pt;text-indent: -36pt;text-align: left;">Continuous Variables: age, performance metrics (goals, assists, appearances), and other quantitative measures reflecting player valuation, form, and contributions.</p></li><li data-list-text="•"><p style="padding-left: 41pt;text-indent: -35pt;line-height: 12pt;text-align: left;">Categorical Variables: Countries and clubs</p></li></ul><p class="s2" style="padding-top: 11pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark4">&zwnj;</a>Objective and Scope</p><p style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">The primary objective is to develop robust predictive models utilising artificial intelligence techniques to estimate players&#39; current market values based on the dataset&#39;s features. By analysing, interpreting, and leveraging these variables, the analysis aims to identify</p><p style="padding-top: 4pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">significant features that drive player valuations, allowing clubs and analysts to make informed, data-driven decisions within the dynamic of competitive football.</p><p class="s1" style="padding-top: 9pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark5">&zwnj;</a>Data Exploration and Pre-processing</p><p style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">The main programming tools we will use for data exploration are Pandas, NumPy, matplotlib and seaborn for visualisation.</p><p style="padding-top: 11pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">After loading our dataset in pandas, we would first like to identify the datatypes of the features we are working with and the amount of data in each feature. From this, we can see that we have a total of 40 columns. Of these columns, we have four columns with the datatype of ‘object’, among which is our target feature, ‘value’.</p><div class="textbox" style="border:0.5pt solid #000000;display:block;left:166.1pt;min-height:14.2pt;top:0.2pt;width:72.7pt;"><p style="padding-top: 3pt;text-indent: 0pt;text-align: center;"><span style=" color: black; font-family:&quot;Times New Roman&quot;, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6.5pt;">Figure 1</span></p></div><p style="text-indent: 0pt;text-align: left;"><span><img width="89" height="240" alt="image" src="d9133cf8-a5d3-449f-bbf9-a7ca0ff921ed_files/Image_001.jpg"/></span></p><p style="padding-top: 11pt;padding-left: 6pt;text-indent: 0pt;text-align: justify;">The feature ‘value’ has the datatype of ‘object’ instead of ‘int’ due to its usage of a currency symbol, this will lead to complications when training the model, so it needs to be converted back to an integer type. This can be done using regex and casting</p><p style="padding-top: 11pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Other object type features, like ‘country’ and ‘club’, may need to be encoded prior to processing. From further investigation into these features (Figure 1), we see that there is a clear order to these values based on their mean value of players assigned to a given club or country. In light of this information, it would be best to encode them using label encoding.</p><p style="padding-top: 11pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">We can see that the marking feature has no value in it at all, so this feature can be dropped as it has no effect on the resulting market value of players. Along with that, we are also able to drop the feature ‘player’, as it is just the names of the players and does not have any relation to the target value. In addition to this, we can identify three counts of duplicate records, so we will remove them to avoid issues arising when building the models.</p><p class="s2" style="padding-top: 11pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark6">&zwnj;</a>Multicollinearity</p><p style="text-indent: 0pt;text-align: left;"><span><img width="128" height="220" alt="image" src="d9133cf8-a5d3-449f-bbf9-a7ca0ff921ed_files/Image_002.jpg"/></span></p><p style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">We can further investigate this dataset to identify correlations between the target and input features as well as across input the features themselves. The former gives a general understanding as to which features are most significant in determining the target; this can prove to be a useful guide when building or improving our model, as it gives a basis for some</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">feature engineering. The latter, on the other hand, gives an important insight into multicollinearity.</p><p style="padding-top: 11pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Multicollinearity refers to the situation where two or more features in a regression or predictive modelling context are highly correlated.</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">You can see a subsection of a generated heat map that shows correlations between every feature. (The full heat map is viewable at the github link.) In this subsection, we are looking specifically at all goalkeeper-related features and as evident by the colour of the cells, these features are extremely high in correlation to each other. When multiple features have high correlation between each other, it is difficult to</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">identify the individual effects that each feature will have on the target. To resolve this, we can make use of a technique called Principle Component Analysis to mitigate multicollinearity by reducing the number of features while retaining most of the original data&#39;s variance. This is achieved by generating orthogonal principal components that capture the maximum variance in the data.</p><p class="s1" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark7">&zwnj;</a>Summary of Methodologies Used</p><p class="s2" style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark8">&zwnj;</a>Support Vector Regression (SVR)</p><p style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">SVR is a machine learning technique used for regression tasks that focuses on fitting a hyperplane that minimizes the error between predicted and actual values in a high- dimensional space, leveraging kernel functions for non-linear transformations. It is effective in capturing non-linear relationships whilst also robust to outliers. With proper parameter tuning, this could end up having the best performance. However, it will lack interpretability and may end up being quite computationally intensive.</p><p class="s2" style="padding-top: 11pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark9">&zwnj;</a>Decision Trees</p><p style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Decision trees partition the feature space into regions based on a series of hierarchical rules, allowing for classification or regression based on attribute values. We will only be using regression trees. Decision trees are a popular pick for simplicity as it offers easy interpretability and insight into feature importance. But it does tend to be prone to overfitting and may struggle with capturing complex relationships in the FIFA datasets.</p><p class="s2" style="padding-top: 11pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark10">&zwnj;</a>Random Forest</p><p style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Random Forest is an ensemble learning method that aggregates multiple decision trees to enhance predictive accuracy and mitigate overfitting and so, it is quite capable of providing reliable data. However, this does mean that the bagging technique it utilises can introduce complexity, which may reduce interpretability. This method is almost in the middle ground between the two previously mentioned methods, which implies it will be the best method for our specific problem.</p><p class="s2" style="padding-top: 11pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark11">&zwnj;</a>Metrics Used</p><p style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">The primary evaluation metrics to assess and compare the performance of all 3 models and their iterative versions were Mean Squared Error (MSE) and R2 (R-squared). The choice of MSE provides insight into the average squared differences between the predicted values and the actual values, emphasising the importance of predictive accuracy. Concurrently, R2 offers a measure of the proportion of variance explained by the models, aiding in understanding their efficacy in capturing underlying relationships. The range of R-square is normally 0 to 1, and the closer the value of R-square is to 1, the better the model fits.</p><p class="s2" style="padding-top: 11pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark12">&zwnj;</a>Data Splitting</p><p style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">The dataset underwent a division into features (X) and the target variable (y), with &#39;value&#39; denoting the market value of players. To facilitate robust model training and assessment, a train-test split was executed with a ratio of 70% for training and 30% for testing. This division ensures that the model is exposed to a substantial amount of data during training, enabling it to learn patterns and relationships effectively. The training set is further split again, with the same ratio, but this time 30% is for validation. This nested split further allows for the optimisation of model hyperparameters on the training-validation subset while maintaining a separate dataset for final unbiased evaluation.</p><p class="s2" style="padding-top: 11pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark13">&zwnj;</a>Learning Curve Analysis</p><p style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">A learning curve was constructed to provide a visual representation of the model&#39;s behaviour across varying training set sizes. The mean and standard deviation of the negative Mean Squared Error (MSE) for both the training and cross-validation sets were computed and graphically depicted against the changing sizes of the training set. This analysis allowed for a comprehensive understanding of how the model&#39;s predictive performance evolves with different amounts of training data, providing insights into potential overfitting or underfitting.</p><p class="s1" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark14">&zwnj;</a>Results and Evaluation</p><p class="s2" style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark15">&zwnj;</a>SVR</p><p style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Originally, for this model, like for all others, we label encoded the categorical features in the dataset (country and club). However, whilst fine-tuning this model, I found that it actually performs much better if these features were completely omitted.</p><p style="text-indent: 0pt;text-align: left;"><span><img width="311" height="200" alt="image" src="d9133cf8-a5d3-449f-bbf9-a7ca0ff921ed_files/Image_003.jpg"/></span></p><p class="s4" style="padding-top: 12pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark16">&zwnj;</a>Learning Curve Analysis</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">It is worth noting that this model had a rather interesting learning curve. The stable cross-validation score indicates that the model&#39;s ability to generalise to unseen data is not improving despite increasing training performance. This could be caused by the SVR model becoming too complex where it captures both the underlying patterns in the data and the noise in the training set. To resolve this, we can make use of hyperparameter-tuning.</p><p class="s4" style="padding-top: 12pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark17">&zwnj;</a>Outcome</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">After hyperparameter-tuning, the best Mean Squared Error (MSE) and R-squared, have significantly improved:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s5" style="padding-left: 5pt;text-indent: 0pt;text-align: left;"><span><img width="244" height="21" alt="image" src="d9133cf8-a5d3-449f-bbf9-a7ca0ff921ed_files/Image_004.jpg"/></span>	<span class="s6"> </span><span><img width="202" height="20" alt="image" src="d9133cf8-a5d3-449f-bbf9-a7ca0ff921ed_files/Image_005.jpg"/></span></p><p style="padding-top: 1pt;text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">Using the generated predictions, we can compare the predicted market value and true market value of all players to plot the graphs of true market values against predicted market values and a residual plot to better visualise the accuracy of this model:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s7" style="padding-left: 6pt;text-indent: 0pt;text-align: left;"><span><img width="285" height="177" alt="image" src="d9133cf8-a5d3-449f-bbf9-a7ca0ff921ed_files/Image_006.jpg"/></span>	<span><img width="284" height="183" alt="image" src="d9133cf8-a5d3-449f-bbf9-a7ca0ff921ed_files/Image_007.jpg"/></span></p><p style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">The closer the blue points are to the dashed line, the closer the predicted market values are to the true market value, meaning that if the blue points are on the red line, the predicted values are equal to the true values. Unfortunately, even with the improvements, it is evident that many predicted results are indeed not accurate; in fact, the points are further from the dashed line when the expected market value is larger, which portrays this modal has a larger variance when trying to estimate large market values. Furthermore, due to the fit of the SVR model, some players’ predicted market values are even negative, so with this in mind and the difficulty in interpreting this model, we concluded that this model is not significantly ideal for predicting and identifying the driving factors behind a player’s market value.</p><p class="s2" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark18">&zwnj;</a>Decision Tree</p><p style="text-indent: 0pt;text-align: left;"><span><img width="301" height="191" alt="image" src="d9133cf8-a5d3-449f-bbf9-a7ca0ff921ed_files/Image_008.jpg"/></span></p><p class="s4" style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark19">&zwnj;</a>Learning Curve Analysis.</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">The plot shown demonstrates one of the many risks discussed beforehand of utilising decision trees, which is their proneness to overfitting to the training set. Although the cross-validation score initially approaches 0, which signifies that the model is improving, you can see that it consistently performs perfectly in predicting values against the training set. This implies that the model is not generalising the data well as the training set increases. This could be the reason why the cross-validation score fluctuates.</p><p class="s4" style="padding-top: 12pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark20">&zwnj;</a>Outcome</p><p style="padding-top: 1pt;padding-bottom: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">After rigorous tuning of the hyperparameters, we only managed to improve the model’s R-Squared score but also increased the Mean Squared Error:</p><p style="text-indent: 0pt;text-align: left;"><span><img width="296" height="33" alt="image" src="d9133cf8-a5d3-449f-bbf9-a7ca0ff921ed_files/Image_009.jpg"/></span><span><img width="326" height="208" alt="image" src="d9133cf8-a5d3-449f-bbf9-a7ca0ff921ed_files/Image_010.jpg"/></span><span><img width="303" height="204" alt="image" src="d9133cf8-a5d3-449f-bbf9-a7ca0ff921ed_files/Image_011.jpg"/></span><span><img width="252" height="32" alt="image" src="d9133cf8-a5d3-449f-bbf9-a7ca0ff921ed_files/Image_012.jpg"/></span></p><p style="padding-top: 10pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Regardless of the increase in the Mean Squared Error, this model still outperforms that of the SVR model. This model greatly benefited from the usage of Principle Component Analysis (PCA) on the goalkeeper fields, making its Mean Squared Error score than that of the SVR model and its R-squared score a large improvement from the previous. These improvements from the previous model are reflected in the plots, where you can see that the blue points, in general, align themselves closer to the dashed line. There are also no negative values, making this overall a much better model to use than our first one.</p><p class="s4" style="padding-top: 12pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark21">&zwnj;</a>Feature Importance</p><p style="text-indent: 0pt;text-align: left;"><span><img width="377" height="204" alt="image" src="d9133cf8-a5d3-449f-bbf9-a7ca0ff921ed_files/Image_013.jpg"/></span></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">With this model generated and working to an acceptable standard, we can now grab the feature importance to identify the driving factors behind a player’s market value. We can see that the most significant features are a player’s ball control and their reactions, followed distantly behind by shots, volleys and short passes.</p><p class="s2" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark22">&zwnj;</a>Random Forest Regression</p><p style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">The Random Forest Regressor was selected as the model of choice due to its inherent capacity to effectively handle non-linear relationships within the dataset and its ability to discern feature importance, making it well-suited for the task of predicting player market values. The model was trained using the designated training set and subsequently tested using the dedicated test set. Following this, predictions were generated on the test set, and key performance metrics, Mean Squared Error (MSE) and R-squared, were computed.</p><p style="text-indent: 0pt;text-align: left;"><span><img width="272" height="171" alt="image" src="d9133cf8-a5d3-449f-bbf9-a7ca0ff921ed_files/Image_014.jpg"/></span></p><p class="s4" style="padding-top: 12pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark23">&zwnj;</a>Learning Curve Analysis.</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Analysing this graph, it can be observed that the cross-validation scores approach 0 as the training size increases, which is expected as the model benefits from more data. It indicates improved model accuracy and predictive power. However, the training scores show a more complex pattern. Initially, the indicating scores decrease, indicating improved generalisation, but at larger training sizes, they start to plateau or even increase. This suggests that the model may be overfitting or encountering difficulties in</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 12pt;text-align: left;">generalising to new data when the training set becomes too large.</p><p style="text-indent: 0pt;text-align: left;"><span><img width="162" height="127" alt="image" src="d9133cf8-a5d3-449f-bbf9-a7ca0ff921ed_files/Image_015.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="174" height="132" alt="image" src="d9133cf8-a5d3-449f-bbf9-a7ca0ff921ed_files/Image_016.jpg"/></span></p><p class="s4" style="padding-top: 12pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark24">&zwnj;</a>Hyperparameter Tuning</p><p class="s8" style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark25">&zwnj;</a>Overall Trends:</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Generally, as the max_depth increases, the model tends to perform better, but there is a risk of overfitting. Lower values of min_samples_split and min_samples_leaf seem to contribute to better performance, but setting them too low might lead to overfitting.</p><p class="s8" style="padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark26">&zwnj;</a>Best Performances:</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">The combination with max_depth = 20, min_samples_split = 2, and min_samples_leaf = 1 seems to have the lowest MSE and a high R2, indicating good predictive performance.</p><p style="padding-top: 1pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s4" style="padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark27">&zwnj;</a>Outcome</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">The model exhibited a lower Mean Squared Error then previous models and a higher R- squared score of 0.8996, indicative of its capability to account for a substantial proportion of the variance in the market values of football players.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s5" style="padding-left: 13pt;text-indent: 0pt;text-align: left;"><span><img width="250" height="25" alt="image" src="d9133cf8-a5d3-449f-bbf9-a7ca0ff921ed_files/Image_017.jpg"/></span>	<span><img width="219" height="29" alt="image" src="d9133cf8-a5d3-449f-bbf9-a7ca0ff921ed_files/Image_018.jpg"/></span></p><p style="padding-top: 7pt;text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">Visualisations, including a scatter plot of actual vs. predicted values and a residual plot, were created to assess the model&#39;s predictive capabilities. The scores achieved by this model are the most successful of all models. This is also conveyed in the plots by the closeness of the blue points to the red line, suggesting it has the least variance in its predictions compared to all other models. This is expected as this is an ensemble learning method which mitigates overfitting, allowing this model to achieve better results than a simpler Decision Tree method. This model is, therefore, the most ideal to use for our problem.</p><p style="padding-top: 11pt;text-indent: 0pt;text-align: left;"><br/></p><p class="s4" style="padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark28">&zwnj;</a>Feature Importance</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">By grabbing the feature importance from the Random Forest model, we see a similarity between this model and the decision tree model, where reactions and ball control are the</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">dominant key features in predicting a player’s market value. However,</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">this model then considers composure and dribbling to be the next most significant instead of volleys and long shots like the decision tree model does.</p><p style="text-indent: 0pt;text-align: left;"><span><img width="55" height="144" alt="image" src="d9133cf8-a5d3-449f-bbf9-a7ca0ff921ed_files/Image_019.jpg"/></span></p><p style="padding-top: 11pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">It is important to remember that during the exploratory data analysis stage, we created a correlation heatmap between the input features and the target (a subsection of this is viewable on the right). The heatmap itself aligns closer to the feature importance ranking established by the Random Forest regression model.</p><p class="s1" style="padding-top: 9pt;padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark29">&zwnj;</a>Evaluation Summary</p><p style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">The evaluation of machine learning models for predicting FIFA player market values provided insightful perspectives on their efficacy, limitations, and applicability within the football ecosystem.</p><p style="padding-top: 11pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Starting with Support Vector Regression (SVR), the model initially demonstrated promising performance metrics, however, it encountered challenges in handling complexity and interpretability. The learning curve analysis and hyperparameter tuning revealed the SVR&#39;s constrained generalisation capabilities; notably, the model&#39;s computational intensity posed significant challenges during tuning, leading to inefficiencies which necessitate future improvement. Despite these limitations, insights into the SVR&#39;s intricacies allow us to learn the need for rigorous optimisation, feature engineering, and computational resources to enhance predictive robustness and mitigate complexities.</p><p style="padding-top: 11pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">In contrast, Decision Trees offered a simple approach, providing interpretability and insights into feature importance. The model&#39;s susceptibility to overfitting, as evidenced by fluctuating cross-validation scores, highlighted the importance of rigorous hyperparameter tuning and feature engineering to balance complexity and performance effectively. Moreover, the Decision Tree&#39;s reliance on specific attributes highlighted the significance of comprehensive data pre-processing and domain expertise to discern meaningful patterns and enhance model reliability.</p><p style="padding-top: 11pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Finally, as expected, the Random Forest Regression model emerged as the best model, leveraging ensemble learning to mitigate overfitting and enhance predictive accuracy. With a far higher R-squared score of 0.8996, the model effectively captured non-linear relationships and discerned key features influencing player valuations. Despite its computational intensity and reduced interpretability compared to individual Decision Trees, the Random Forest&#39;s superior performance and minimal variance in predictions underscored its potential as a strategic tool for stakeholders in navigating player transfers, contract negotiations, and market dynamics.</p><p style="padding-top: 11pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">In summary, the Random Forest Regression model demonstrated better predictive capabilities out of the explored models. However, it&#39;s crucial to acknowledge that each model has its strengths and weaknesses. The difficulty of achieving perfection emphasises the</p><p style="text-indent: 0pt;text-align: left;"><span><img width="388" height="210" alt="image" src="d9133cf8-a5d3-449f-bbf9-a7ca0ff921ed_files/Image_020.jpg"/></span><span><img width="322" height="209" alt="image" src="d9133cf8-a5d3-449f-bbf9-a7ca0ff921ed_files/Image_021.jpg"/></span><span><img width="337" height="212" alt="image" src="d9133cf8-a5d3-449f-bbf9-a7ca0ff921ed_files/Image_022.jpg"/></span></p><p style="padding-top: 4pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">ongoing need for refinement, validation, and collaboration with domain experts to navigate the evolving complexities and biases in the football world.</p><p style="padding-top: 11pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Moreover, there are many limitations to consider. For instance, the dataset used does not account for a player&#39;s popularity, which could influence their market value. Exploring such factors alongside domain experts is essential for a more comprehensive understanding of player valuation in the football industry. Future research could delve into hybrid approaches, leveraging multiple datasets to capture a more holistic understanding of player valuation, including factors like popularity, which may significantly influence market value but remain unexplored in the current dataset.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s1" style="padding-left: 6pt;text-indent: 0pt;text-align: left;"><a name="bookmark30">&zwnj;</a>References</p><p style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Europa.eu. (2024). <i>EUR-Lex - 61993CJ0415 - EN - EUR-Lex</i>. [online] Available at: <u>https://</u> <u>eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:61993CJ0415</u> [Accessed 1 Jan. 2024].</p><p style="padding-top: 11pt;padding-left: 9pt;text-indent: 0pt;line-height: 12pt;text-align: left;">MEN PROFESSIONAL FOOTBALL A REVIEW OF INTERNATIONAL FOOTBALL</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: left;">TRANSFERS WORLDWIDE. (n.d.). Available at: <u>https://digitalhub.fifa.com/m/</u> <u>248987d86f2b9955/original/x2wrqjstwjoailnncnod-pdf.pdf</u>.</p><p style="padding-top: 12pt;padding-left: 6pt;text-indent: 3pt;text-align: left;">Herm, S., Callsen-Bracker, H.-M. and Kreis, H. (2014). When the crowd evaluates soccer players’ market values: Accuracy and evaluation attributes of an online community. <i>Sport Management Review</i>, 17(4), pp.484–492. doi:https://doi.org/10.1016/j.smr.2013.12.006.</p><p style="padding-top: 11pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Kaplan, T. (2010). When It Comes to Stats, Soccer Seldom Counts. <i>The New York Times</i>. [online] 8 Jul. Available at: <a href="http://www.nytimes.com/2010/07/09/sports/soccer/" class="a" target="_blank">https://</a><span class="s11">www.nytimes.com/2010/07/09/sports/soccer/</span> <span class="s11">09soccerstats.html</span>.</p></body></html>
